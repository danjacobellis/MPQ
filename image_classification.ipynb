{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1607de3b-cd13-4ca2-ad44-2262687b966e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-12 10:18:35.334039: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-10-12 10:18:35.373394: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-12 10:18:35.794145: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from utils import jpeg_compress, webp_compress, pad, crop, nn_compress, hific_lo_compress\n",
    "import compressai\n",
    "from evaluate import evaluator\n",
    "from transformers import pipeline\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84fd1a2b-1e83-4616-a48b-7430e53bc33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "net_mbt2018 = compressai.zoo.mbt2018(quality=1, pretrained=True).eval().to(device)\n",
    "def mbt2018_compress(sample):\n",
    "    return nn_compress(sample,net_mbt2018,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "87b13540-6ab3-4f4f-9d97-4cfebb87a34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_compression_methods = [\n",
    "    jpeg_compress,\n",
    "    webp_compress,\n",
    "    mbt2018_compress,\n",
    "    hific_lo_compress\n",
    "]\n",
    "models = [\n",
    "    \"microsoft/resnet-18\",\n",
    "    \"google/vit-base-patch16-224\",\n",
    "    \"microsoft/beit-large-patch16-224\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f76036d-fe12-41dc-94ec-79f4cbd67624",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet = [load_dataset(\"imagenet-1k\", split=\"validation[:1000]\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47367119-9e4d-4d79-bb77-736b2f31fe8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for method in image_compression_methods:\n",
    "    imagenet.append(imagenet[0].map(method))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "00e63ecd-c4c8-4074-95a0-a52592fcea42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n",
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n"
     ]
    }
   ],
   "source": [
    "pipe = []\n",
    "for model in models:\n",
    "    pipe.append(\n",
    "        pipeline(\n",
    "            task=\"image-classification\",\n",
    "            model=model,\n",
    "            device=\"cuda:0\"\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "958b4f9a-98c7-4f3d-a797-ea9c0bb70011",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_evaluator = evaluator(\"image-classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f15b035f-8289-4ee2-b455-5bf650a99f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results = []\n",
    "for i_method,method in enumerate(imagenet):\n",
    "    eval_results.append([])\n",
    "    for i_model,model in enumerate(pipe):\n",
    "        eval_results[i_method].append(\n",
    "            task_evaluator.compute(\n",
    "                model_or_pipeline=model,\n",
    "                data=method,\n",
    "                metric=\"accuracy\",\n",
    "                label_mapping=model.model.config.label2id\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "13678892-ae6f-4653-9c50-59007aa526d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.698, 0.799, 0.873],\n",
       " [0.394, 0.639, 0.794],\n",
       " [0.505, 0.72, 0.819],\n",
       " [0.488, 0.664, 0.756],\n",
       " [0.688, 0.796, 0.873]]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[rij['accuracy'] for rij in r] for r in eval_results]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
