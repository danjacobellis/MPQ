{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "449da814-ea8d-4800-aee6-39b1a7a6fdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from utils import mp3_compress, opus_compress, encodec_compress\n",
    "from utils import hf_audio_encode\n",
    "from transformers import pipeline\n",
    "from evaluate import evaluator\n",
    "import encodec\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cdpam\n",
    "import torch\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cd696aa-693f-42ac-a4b0-2c3e9312c5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mp3_compress_cv(sample):\n",
    "    audio = sample['audio']['array'].unsqueeze(0)\n",
    "    fs = sample['audio']['sampling_rate']\n",
    "    audio,bps = mp3_compress(audio,fs)\n",
    "    encoded = hf_audio_encode(audio,fs)\n",
    "    sample['audio'] = encoded\n",
    "    sample['bps'] = bps\n",
    "    return sample\n",
    "def opus_compress_cv(sample):\n",
    "    audio = sample['audio']['array'].unsqueeze(0)\n",
    "    fs = sample['audio']['sampling_rate']\n",
    "    audio,bps = opus_compress(audio,fs)\n",
    "    encoded = hf_audio_encode(audio,fs)\n",
    "    sample['audio'] = encoded\n",
    "    sample['bps'] = bps\n",
    "    return sample\n",
    "\n",
    "device = \"cuda\"\n",
    "encodec_model_48_3 = encodec.EncodecModel.encodec_model_48khz()\n",
    "encodec_model_48_3.set_target_bandwidth(6)\n",
    "encodec_model_48_3.to(device)\n",
    "def encodec_48_3_compress(sample):\n",
    "    audio = sample['audio']['array'].unsqueeze(0)\n",
    "    fs = sample['audio']['sampling_rate']\n",
    "    audio,bps = encodec_compress(audio,fs, encodec_model_48_3, device)\n",
    "    encoded = hf_audio_encode(audio,fs)\n",
    "    sample['audio'] = encoded\n",
    "    sample['bps'] = bps\n",
    "    return sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b215ebd8-3c13-4511-baa5-c519e2f7539e",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_compression_methods = [\n",
    "    mp3_compress_cv,\n",
    "    opus_compress_cv,\n",
    "    encodec_48_3_compress\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aab3f0a9-b5c3-4e2f-b799-7644fd8e0cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_voice = load_dataset(\"mozilla-foundation/common_voice_11_0\",\n",
    "                             \"en\",\n",
    "                             split=\"validation[:100]\"\n",
    "                            ).with_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "395ef5e4-ca47-485f-832e-9f0be540dddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'indices'=<generator object <genexpr> at 0x7f1daf478040> of the transform datasets.arrow_dataset.Dataset.select couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    }
   ],
   "source": [
    "exclude_idx = [362, 711]\n",
    "common_voice = [common_voice.select(\n",
    "    (\n",
    "        i for i in range(len(common_voice)) \n",
    "        if i not in set(exclude_idx)\n",
    "    )\n",
    ")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14780f0d-32e3-442c-bf73-5ca72865d272",
   "metadata": {},
   "outputs": [],
   "source": [
    "for method in audio_compression_methods:\n",
    "    common_voice.append(common_voice[0].map(method))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2d5e7bc9-919c-4d0e-9b8d-13807e16c4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdpam_metric = cdpam.CDPAM()\n",
    "mse_metric = torch.nn.MSELoss()\n",
    "cdpam_distance = []\n",
    "mse_distance = []\n",
    "for dataset in common_voice:\n",
    "    cdpam_distance.append([])\n",
    "    mse_distance.append([])\n",
    "    for i_sample,sample in enumerate(common_voice[0]):\n",
    "        compressed_sample = dataset[i_sample]\n",
    "        sample_rate = sample['audio']['sampling_rate']\n",
    "        reference = sample['audio']['array'].unsqueeze(0)\n",
    "        distorted = compressed_sample['audio']['array'].unsqueeze(0)\n",
    "        cdpam_distance[-1].append(cdpam_metric.forward(reference,distorted).detach().cpu().item())\n",
    "        mse_distance[-1].append(mse_metric.forward(reference,distorted).detach().cpu().item())\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8f54aaec-3a47-43cb-a7ac-f25926d79817",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1280223/1022136466.py:1: RuntimeWarning: divide by zero encountered in log10\n",
      "  PSNR = [-10*np.log10(np.mean(d)) for d in mse_distance][1:]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[33.898382799187345, 26.702614854902365, 29.0428171579391]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PSNR = [-10*np.log10(np.mean(d)) for d in mse_distance][1:]\n",
    "PSNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4a95d0ac-230b-42dd-8f80-8f79aac8ef9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1280223/66541421.py:1: RuntimeWarning: divide by zero encountered in log10\n",
      "  cdpam_PSNR = [-10*np.log10(np.mean(d)) for d in cdpam_distance][1:]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[37.89975888664649, 38.27911434099799, 46.34223939544932]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdpam_PSNR = [-10*np.log10(np.mean(d)) for d in cdpam_distance][1:]\n",
    "cdpam_PSNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b52196d6-9ee7-4cc9-9c3a-4d7253d51d52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6696820259094238, 0.14399589598178864, 0.12622858583927155]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_bps = [method['bps'].mean().item() for method in common_voice[1:]]\n",
    "audio_bps"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
